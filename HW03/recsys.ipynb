{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9HX7zcUgDB0m"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "class MatrixFactorization:\n",
        "    def __init__(self, num_items, num_users, num_factors, learning_rate, regularization_rate, num_iterations):\n",
        "        \"\"\"\n",
        "        Initialize the Matrix Factorization model.\n",
        "\n",
        "        Args:\n",
        "            num_items (int): Number of items.\n",
        "            num_users (int): Number of users.\n",
        "            num_factors (int): Number of latent factors.\n",
        "            learning_rate (float): Learning rate for gradient descent.\n",
        "            regularization_rate (float): Regularization rate for L2 regularization.\n",
        "            num_iterations (int): Number of iterations for training.\n",
        "        \"\"\"\n",
        "        self.num_items = num_items\n",
        "        self.num_users = num_users\n",
        "        self.num_factors = num_factors\n",
        "        self.learning_rate = learning_rate\n",
        "        self.regularization_rate = regularization_rate\n",
        "        self.num_iterations = num_iterations\n",
        "\n",
        "        # Initialize Q and P matrices with random values\n",
        "        # Start your code\n",
        "        self.Q = np.random.rand(self.num_items, self.num_factors)\n",
        "        self.P = np.random.rand(self.num_users, self.num_factors)\n",
        "        # End your code\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        \"\"\"\n",
        "        Compute the sigmoid function.\n",
        "\n",
        "        Args:\n",
        "            x (float): Input value.\n",
        "\n",
        "        Returns:\n",
        "            float: Sigmoid value.\n",
        "        \"\"\"\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def update_parameters(self, R):\n",
        "        \"\"\"\n",
        "        Update the parameters Q and P using Stochastic Gradient Descent.\n",
        "\n",
        "        Args:\n",
        "            R (ndarray): Rating matrix.\n",
        "        \"\"\"\n",
        "        # Start your code\n",
        "        for i in range(self.num_items):\n",
        "            for u in range(self.num_users):\n",
        "                if R[i, u] == 0:\n",
        "                    continue\n",
        "                error =  np.log(self.sigmoid(R[i, u] - np.dot(self.Q[i], self.P[u])))\n",
        "                self.Q[i] += self.learning_rate * (error * self.P[u] - self.regularization_rate * self.Q[i])\n",
        "                self.P[u] += self.learning_rate * (error * self.Q[i] - self.regularization_rate * self.P[u])\n",
        "        # End your code\n",
        "\n",
        "    def train(self, R):\n",
        "        \"\"\"\n",
        "        Train the Matrix Factorization model.\n",
        "\n",
        "        Args:\n",
        "            R (ndarray): Rating matrix.\n",
        "        \"\"\"\n",
        "        self.update_parameters(R)\n",
        "\n",
        "    def predict_rating(self, i, u):\n",
        "        \"\"\"\n",
        "        Predict the rating for item i and user u.\n",
        "\n",
        "        Args:\n",
        "            i (int): Item index.\n",
        "            u (int): User index.\n",
        "\n",
        "        Returns:\n",
        "            float: Predicted rating.\n",
        "        \"\"\"\n",
        "        # Start your code\n",
        "        return self.sigmoid(np.dot(self.Q[i], self.P[u]))\n",
        "        # End your code\n",
        "\n",
        "    def evaluate(self, users_list, groundTruth_list, topk):\n",
        "            \"\"\"\n",
        "            Evaluate the trained model for a list of users and calculate the accuracy.\n",
        "\n",
        "            Args:\n",
        "                users_list (list): List of user indexes.\n",
        "                groundTruth_list (list): List of ground truth items in the user's test set.\n",
        "                topk (int): Threshold for top-k item selection.\n",
        "\n",
        "            Returns:\n",
        "                float: Accuracy of the model.\n",
        "            \"\"\"\n",
        "            accuracies = []\n",
        "\n",
        "            for u, groundTruth in zip(users_list, groundTruth_list):\n",
        "                predicted_ratings = [self.predict_rating(i, u) for i in range(self.num_items)]\n",
        "                topk_indices = np.argsort(predicted_ratings)[-topk:]\n",
        "                intersection = len(set(topk_indices) & set(groundTruth))\n",
        "                accuracy = intersection / len(groundTruth)\n",
        "                accuracies.append(accuracy)\n",
        "\n",
        "            return np.mean(accuracies)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "file_path = \"/content/data.txt\"\n",
        "\n",
        "with open(file_path, \"r\") as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "lines = [line.strip() for line in lines if line.strip() != '']\n",
        "num_users = len(lines)\n",
        "\n",
        "max_item = 0\n",
        "user_items = []\n",
        "\n",
        "for line in lines:\n",
        "    words = line.split(\" \")\n",
        "    user_id = int(words[0])\n",
        "    items = [int(word) for word in words[1:]]\n",
        "    max_item = max(max_item, max(items))\n",
        "    user_items.append((user_id, items))\n",
        "\n",
        "num_items = max_item + 1\n",
        "R = np.zeros((num_users, num_items), dtype=np.int8)\n",
        "\n",
        "for user_id, items in user_items:\n",
        "    num_items_to_remove = int(0.2 * len(items))\n",
        "    items_to_remove = np.random.choice(items, num_items_to_remove, replace=False)\n",
        "    items = list(set(items) - set(items_to_remove))\n",
        "    R[user_id, items] = 1\n",
        "\n",
        "# Splitting into training set and test set\n",
        "test_size = int(0.4 * num_users)\n",
        "test_indices = np.random.choice(range(num_users), test_size, replace=False)\n",
        "test_set = R[test_indices]\n",
        "train_set = np.delete(R, test_indices, axis=0)\n",
        "\n",
        "print(\"Training set:\")\n",
        "print(train_set)\n",
        "\n",
        "print(\"Test set:\")\n",
        "print(test_set)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyM53RKUElV2",
        "outputId": "b1ddab14-dff9-42dc-9211-8b797e1a9249"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set:\n",
            "[[0 1 1 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "Test set:\n",
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_set.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-0EHmtIDVEZ",
        "outputId": "d8de6a48-3b16-463f-cbbc-427ca8d9446c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11943, 40981)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_set.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0LnVBf0DXuw",
        "outputId": "74bd5822-0b3f-435f-c513-19e4ba7e5094"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17915, 40981)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HW5UXASUDB0r",
        "outputId": "1838e60a-91db-479d-838c-d7488cf8bcae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted rating for item 0 and user 0: 0.8862937470958735\n",
            "Accuracy for model with learning rate 0.001: 0.0014215686274509803\n",
            "\n",
            "Predicted rating for item 0 and user 0: 0.21461710624541544\n",
            "Accuracy for model with learning rate 0.1: 0.000588235294117647\n",
            "\n",
            "Predicted rating for item 0 and user 0: 0.6851547681666874\n",
            "Accuracy for model with learning rate 0.01: 0.001\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Example usage\n",
        "num_items = 100\n",
        "num_users = 100\n",
        "num_factors = 10\n",
        "learning_rates = [0.001, 0.1, 0.01]\n",
        "regularization_rate = 0.1\n",
        "num_iterations = 100\n",
        "\n",
        "R_train = train_set  # Rating matrix for training\n",
        "R_test = test_set  # Rating matrix for testing\n",
        "\n",
        "for learning_rate in learning_rates:\n",
        "    model = MatrixFactorization(num_items, num_users, num_factors, learning_rate, regularization_rate, num_iterations)\n",
        "    model.train(R_train)\n",
        "\n",
        "    # Test prediction for item 0 and user 0\n",
        "    item_index = 0\n",
        "    user_index = 0\n",
        "    prediction = model.predict_rating(item_index, user_index)\n",
        "    print(f\"Predicted rating for item {item_index} and user {user_index}: {prediction}\")\n",
        "\n",
        "    # Evaluate model on test data\n",
        "    user_indexes = list(range(num_users))  # List of all user indexes in the test set\n",
        "    groundTruths = []  # List of ground truth items for each user in the test set\n",
        "\n",
        "    for user_index in user_indexes:\n",
        "        groundTruth = np.where(R_test[user_index] > 0)[0]  # Ground truth items for the current user\n",
        "        groundTruths.append(groundTruth)\n",
        "\n",
        "    topk = 10  # Top-k threshold\n",
        "\n",
        "    accuracy = model.evaluate(user_indexes, groundTruths, topk)\n",
        "    print(f\"Accuracy for model with learning rate {learning_rate}: {accuracy}\\n\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}